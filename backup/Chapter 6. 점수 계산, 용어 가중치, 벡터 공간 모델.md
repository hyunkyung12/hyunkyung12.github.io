# Chapter 6. 점수 계산, 용어 가중치, 벡터 공간 모델 

> 이 글은 [최신 정보검색론](<https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf>) 을 읽고 정리 한 내용입니다.



Boolean 질의로 매칭되는 문헌들을 찾았을 때, 그 문헌들에 점수를 부여해 순서를 정하는 과정이 필요합니다.

Chapter 6 에서는 그 방법들에 대해 다루겠습니다.



### 6.1 인수 색인과 구역 색인



문헌은 용어 뿐 아니라 **메타 데이터** 를 포함한 구조입니다. 메타 데이터란 저자, 제목, 출판일 등 문헌의 기본 정보를 의미합니다.

검색 결과에 점수를 부여할 때, 이 메타 데이터를 활용할 수 있습니다. 메타 데이터 중 값이 작은것을 **필드**, 값이 비교적 큰 것을 **구역**이라고 하는데 주로 구역에 대해 살펴보겠습니다.



#### 1) 가중치 구역 점수 계산

메타 데이터의 각 구역에 **가중치**를 부여해 매칭 정도를 계산하면, 점수를 매길 수 있는 형태가 됩니다.

예를 들어,

| 문헌 ID | 저자   | 제목                 | 본문            |
| :------ | ------ | -------------------- | --------------- |
| 1       | 현경   | 고양이 좋아          | 고양이가 최고야 |
| 2       | 고양이 | 고양이가 좋아하는 것 | 츄르가 최고야   |

위의 자료에서 저자, 제목, 본문에 각각 가중치 $ 0.2 , 0.3, 0.5​$ 를 부여한다고 합시다.

쿼리가 '고양이' 일 때, 문헌 1의 점수는 $ 0.2 * 0 + 0.3 * 1 + 0.5*1 = 0.8 $ 이고, 문헌 2의 점수는 $ 0.5 $ 입니다.

두 문헌 모두 '고양이' 라는 단어를 두번씩 포함하지만, 본문에 가중치를 높게 주었기 때문에 문헌1의 점수가 더 높습니다.

이렇게 더 중요하다고 생각하는 구역에 가중치를 높게 줌으로써 순위를 정할 수 있었습니다.



**그렇다면 이 가중치는 어떻게 구할까요?**

위의 예제처럼 값을 지정해 사용할 수도 있지만, 일반적으로는 최적의 값을 찾기 위해 **학습** 을 합니다.

학습을 위한 데이터셋은 보통 (질의 q, 문헌 d, 적합성여부) 로 구성 됩니다. 가중치는 g 입니다.

제목(T)와 본문(B)에 대한 가중치를 구하는 경우를 생각해 보면,

$ score(d_j, q_j) = g * s_T(d_j, q_j) + (1-g) * s_B(d_j, q_j) ​$ 인 식을 생각할 수 있습니다.

모든 구역에 대한 가중치 합은 1이고, $ s_T $와 $ s_B $는 각각 쿼리와 제목,본문의 일치 여부에 대한 Boolean값입니다.

이 score 값을 데이터셋의 적합성 여부와 비교해, 다음과 같이 오차함수를 정의할 수 있습니다.

$ \epsilon(d_j, q_j) = (r(d_j, q_j) - score(d_j, q_j))^2 $

그렇다면 총 오류는 모든 데이터 쌍에 대한 $ \epsilon ​$ 값의 합이 됩니다. 

결과적으로, **총 오류를 최소로 만드는 가중치 g의 값을 찾는 것**이 최적의 가중치를 찾는 것임을 알 수 있습니다.

이 문제는 g 에 대한 이차식이 최소가 되는 점, 즉 **미분해서 0이 되는 점**을 찾으면 되는 문제입니다.

 

### 6.2 용어 빈도와 가중치



1) 에서는 구역에 가중치를 부여했다면, 2)에서는 **문헌 내 용어**에 가중치를 부여합니다.

문헌1과 2에 동일한 단어가 있는데, 그 단어의 중요성이 문헌1보다 2에서 크다면 문헌2에 높은 점수를 주는 것입니다. 즉, 문헌에서 중요한 단어를 포함하는지를 살펴보는 것입니다.

이 절에서는 빈도 관련 용어가 많이 나오기 때문에 용어를 정리해 보겠습니다.

- 용어 빈도 (tf) : 문헌 d 내에서 용어 t의 빈도
- 문헌 빈도 (df) : 컬렉션 c 내에서 용어 t를 포함하는 문헌의 수
- 역문헌 빈도 (idf) : $ log(\frac {N} {df}) ​$ 

용어에 가중치를 주는 가장 간단한 방법은 문헌 내 용어의 빈도 (**tf**) 를 세는 것 입니다.

하지만 이 방법은 문제가 있습니다. 예를 들어 고양이 서적 관련 컬렉션에서 용어 '고양이 화장실'를 찾는 경우를 생각해봅시다.  ~~너무 극단적이네요...~~ 

| 문헌 1                                             | 문헌 2               | 문헌 3 |
| -------------------------------------------------- | -------------------- | ------ |
| 고양이 ... 고양이 ... 고양이 ... 고양이 ... 고양이 | 고양이 고양이 화장실 | 화장실 |

문헌 1 에서 고양이의 빈도는 5, 문헌 2 에서 고양이의 빈도는 2 이므로 빈도 수만 생각해본다면 '고양이 화장실'의 검색결과는 문헌 1로 잘못 나오게 됩니다.

고양이 서적 관련 컬렉션에서는 모든 문헌이 대체적으로 '고양이'를 많이 포함하고 있기 때문에 '고양이'보다는 '화장실'에 집중하는 것이 좋습니다. 그러기 위해서는 '고양이'의 많은 빈도를 조절해 중요도를 낮추어 주어야 합니다.

빈도 조절을 위해 컬렉션 내에서 '고양이'를 포함하는 문헌의 수 (**df**) 를 세어줍니다. 위의 예에서는 2 입니다.

'고양이'를 포함하는 문헌이 많을 수록 그 용어를 덜 중요하게 보고 싶기 때문에, 전체 문헌 수 (N) 를 df 로 나누어 줍니다. 이 값을 역문헌 빈도 (**idf**) 라고 하고,  $ idf = log(\frac {N} {df}) ​$ 로 정의해 줍니다. (log 는 계산량을 줄이기 위해 사용합니다.)

이제 빈도 조절까지 완료했으므로, tf 와 idf를 결합한 **tf-idf** 를 문헌 내 용어의 가중치로 사용할 것이며, 식은 $ {tf-idf}_{t,d}  = tf_{t,d} * idf_t$ 입니다.



결과적으로 tf-idf 값은

- 적은 수의 문헌에 용어 t가 많이 있으면 가장 높은 값을 가짐
- 문헌들에 그 용어가 적게 있으면 적은 값을 가짐
- 모든 문헌 안에 용어가 존재할 경우 가장 낮은 값을 가짐

으로 생각할 수 있겠습니다.



### 6.3 점수 계산을 위한 벡터 공간 모델



위에서는 문헌을 용어들의 집합으로 생각했습니다. 이번 절에서는 문헌을 **벡터 공간** 안에 있는것으로 생각해 보겠습니다.





















































